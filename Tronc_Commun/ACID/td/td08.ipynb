{"cells":[{"cell_type":"markdown","metadata":{},"source":["\n","<h4 id=\"Université-de-Bordeaux,--Master-Mention-Informatique,--2021-2022\">Université de Bordeaux,  Master Mention Informatique,  2021-2022<a class=\"anchor-link\" href=\"#Université-de-Bordeaux,--Master-Mention-Informatique,--2021-2022\">¶</a></h4><h1 id=\"Analyse,-classification-et-indexation-des-données:-feuille-8\">Analyse, classification et indexation des données: feuille 8<a class=\"anchor-link\" href=\"#Analyse,-classification-et-indexation-des-données:-feuille-8\">¶</a></h1><h3 id=\"Apprentissage-supervisé,-Arbres-de-décision-et-Forêts-aléatoires\">Apprentissage supervisé, Arbres de décision et Forêts aléatoires<a class=\"anchor-link\" href=\"#Apprentissage-supervisé,-Arbres-de-décision-et-Forêts-aléatoires\">¶</a></h3>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h3 id=\"Avant-propos\">Avant propos<a class=\"anchor-link\" href=\"#Avant-propos\">¶</a></h3><p>Dans cette feuille, nous allons étudier une catégorie d'algorithmes d'apprentissage supervisé différente de ce que nous avons vue jusque là :</p>\n","<ul>\n","<li><p>les arbres de décisions ont ce la de particulier qu'ils sont construits en utilisant des éléments de la théorie de l'information. Leur utilisation, ensuite, est assez facilement implémentable par des règles Si-Sinon simples.</p>\n","</li>\n","<li><p>les forêts aléatoires implémentent, elles, une approche de bagging.</p>\n","</li>\n","</ul>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<p>Commençons par charger quelques bibliothèques utiles.</p>\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["\n","import numpy as np\n","import pandas as pa\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h3 id=\"Exercice-1.-Arbres-de-décision-(à-la-main)\">Exercice 1. Arbres de décision (à la main)<a class=\"anchor-link\" href=\"#Exercice-1.-Arbres-de-décision-(à-la-main)\">¶</a></h3><p>Dans ce premier exercice, nous allons écrire un ensemble de fonction implémentant les éléments vus en cours et permettant de construire un arbre de décision.</p>\n","<p>Pour vérifier vos fonctions, vous pouvez essayer des les appliquer à l'exemple très simple vu en cours :</p>\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["\n","exemple_cours = pa.DataFrame(data={'A': [0, 0, 1, 1],\n","                                  'B': [1, 0, 1, 0],\n","                                  'Classe': ['C1', 'C1', 'C2', 'C2']})\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>Ecrire une fonction <code>information(dataset, label_feature)</code> permettant de calculer la quantité d'information nécessaire pour classifier un élément du corpus <code>dataset</code>. Le paramètre <code>label_feature</code> indique la colonne contenant les classes des éléments.</li>\n","</ol>\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["4.0"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["\n"," \n","def information(dataset,label_feature):\n","    classes= np.unique(dataset[label_feature])\n","    p = dataset[label_feature].value_counts()[0]\n","    n = dataset.shape[0] - p\n","    return -p*np.log2(p/(p+n)) - n*np.log2(n/(p+n))\n","\n","\n","\n","exemple_cours\n","information(exemple_cours,'Classe')"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>Ecrire une fonction <code>entropy(dataset, feature, label_feature)</code> calculant l'entropie du descripteur <code>feature</code></li>\n","</ol>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def entropy(dataset, feature, label_feature):\n","    \n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>Ecrire une fonction <code>gain(dataset, feature, label_feature)</code> calculant le gain d'information obtenu en choisissant le descripteur <code>feature</code> pour partitionner le corpus <code>dataset</code></li>\n","</ol>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>En vous aidant des fonctions que vous avez écrite ci-dessus, construisez l'arbre de décision (pour Achat) pour le corpus suivant. On ne demande pas d'écrire un programme qui construit l'arbre mais plutôt d'utiliser les fonctions pour faire les calculs à votre place.</li>\n","</ol>\n","\\begin{array}{|c|c|c|c|c|}\n","\\hline\n","\\hline\n","Sexe &amp; Age &amp; Etat civil &amp; Revenu &amp; Achat \\\\\n","\\hline\n","Homme &amp; 18-35   &amp; Marie       &amp; Moyen  &amp; Non \\\\\n","Homme &amp; &lt;18     &amp; Celibataire &amp; Faible &amp; Non \\\\\n","Homme &amp; &gt;35     &amp; Marie       &amp; Eleve  &amp; Oui \\\\\n","Femme &amp; &lt;18     &amp; Celibataire &amp; Moyen  &amp; Non \\\\\n","Homme &amp; 18 - 35 &amp; Celibataire &amp; Moyen  &amp; Non \\\\\n","Femme &amp; 18 - 35 &amp; Celibataire &amp; Eleve  &amp; Oui \\\\\n","Femme &amp; 18 - 35 &amp; Marie       &amp; Faible &amp; Non \\\\\n","Homme &amp; 18 - 35 &amp; Marie       &amp; Eleve  &amp; Oui \\\\\n","Homme &amp; &gt;35     &amp; Celibataire &amp; Faible &amp; Oui \\\\\n","Femme &amp; &lt;18     &amp; Celibataire &amp; Moyen  &amp; Non \\\\\n","Femme &amp; &gt;35     &amp; Celibataire &amp; Moyen  &amp; Oui \\\\\n","Femme &amp; &gt;35     &amp; Marie       &amp; Eleve  &amp; Oui \\\\\n","Homme &amp; 18 - 35 &amp; Celibataire &amp; Faible &amp; Non\\\\\n","Femme &amp; 18 - 35 &amp; Marie       &amp; Moyen  &amp; Oui\\\\\n","\\hline\n","\\hline\n","\\end{array}\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>Dessiner l'arbre de décision obtenu.</li>\n","</ol>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h2 id=\"Exercice-2.-Arbres-de-décision-avec-sklearn\">Exercice 2. Arbres de décision avec <code>sklearn</code><a class=\"anchor-link\" href=\"#Exercice-2.-Arbres-de-décision-avec-sklearn\">¶</a></h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<p>Dans cet exercice, nous allons utiliser la bibliothèque <code>sklearn</code> pour entraîner et tester un arbre de décision.</p>\n","<p>Pour cela, nous allons utiliser le corpus <code>titanic.csv</code>. Un échantillon de ce corpus est diponible à l'adresse :</p>\n","<p><a href=\"https://www.labri.fr/perso/zemmari/datasets/titanic.csv\">https://www.labri.fr/perso/zemmari/datasets/titanic.csv</a></p>\n","<p>Une description détaillée de ce corpus et des descripteurs le composant peut être consultée à l'adresse :</p>\n","<p><a href=\"https://www.kaggle.com/c/titanic/data\">https://www.kaggle.com/c/titanic/data</a></p>\n","<p>On vous laisse découvrir la tragédie à laquelle est lié ce corpus :-)</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>Chargez le corpus et explorez son contenu.</li>\n","</ol>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>Supprimez les lignes contenant des données monquantes</li>\n","</ol>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>On souhaite construire un modèle pour prédire, pour un passager, s'il survivera ou non. Supprimez les descripteurs qui ne vous paraissent pas pertinents pour la prédiction. Expliquez vos choix.</li>\n","</ol>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>La cellule suivante permet de convertir une catégorie au format entier ou au format texte en un entier. \n","Exécuter la telle que'elle et obeservez son résultat.</li>\n","</ol>\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'dataset' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ff366535776a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"]}],"source":["\n","from sklearn import preprocessing\n","\n","cols = ['Sex', 'Embarked']\n","le = preprocessing.LabelEncoder()\n","for c in cols:\n","    le.fit(dataset[c])\n","    dataset[c] = le.transform(dataset[c])\n","dataset\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>Séparez les données en un ensembe $X$ contenant les variables explcatives et $y$ la variable à prédire.</li>\n","</ol>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>Partitionnez les données en partie pour l'entraînelment et une pour le test</li>\n","</ol>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>Instanciez un classifieur Decision Tree et entraînez-le avec les données d'entraînement.</li>\n","</ol>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>Visualisez l'arbre obtenu. complétez pour cela le code suivant</li>\n","</ol>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","from sklearn.tree import export_graphviz\n","from sklearn.externals.six import StringIO  \n","from IPython.display import Image  \n","import pydotplus\n","\n","features_cols = ....\n","\n","class_names=['0','1']\n","visualize(dt, features_cols, class_names)\n","\n","dot_data = StringIO()\n","export_graphviz(dt, out_file=dot_data,  \n","                filled=True, rounded=True,\n","                special_characters=True,feature_names = features_cols,class_names=class_names)\n","graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n","#graph.write_png('titanic.png')\n","Image(graph.create_png())\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>Mesurez la qualité de votre classifieur.</li>\n","</ol>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<ol>\n","<li>Changez les valeurs par défaut des différents paramètres et observez la qualité de votre classifieur. </li>\n","</ol>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","                \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h2 id=\"Exercice-3.-Random-forest\">Exercice 3. Random forest<a class=\"anchor-link\" href=\"#Exercice-3.-Random-forest\">¶</a></h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<p>Quelles sont les performances d'un classifieur de type forêts aléatoires sur le même corpus que l'exercice précédant ?</p>\n","<p>Cherchez le meilleur paramètrage pour le meilleur clasifieur.</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","import numpy as np\n","from sklearn.model_selection import RandomizedSearchCV\n","# Number of trees in random forest\n","n_estimators = ....\n","# Number of features to consider at every split\n","max_features = ...\n","# Maximum number of levels in tree\n","max_depth = ...\n","max_depth.append(None)\n","# Minimum number of samples required to split a node\n","min_samples_split = ...\n","# Minimum number of samples required at each leaf node\n","min_samples_leaf = ...\n","# Method of selecting samples for training each tree\n","bootstrap = [True, False]\n","# Create the random grid\n","random_grid = {'n_estimators': n_estimators,\n","               'max_features': max_features,\n","               'max_depth': max_depth,\n","               'min_samples_split': min_samples_split,\n","               'min_samples_leaf': min_samples_leaf,\n","               'bootstrap': bootstrap}\n","print(random_grid)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Use the random grid to search for best hyperparameters\n","# First create the base model to tune\n","rf = RandomForestClassifier()\n","# Random search of parameters, using 3 fold cross validation, \n","# search across 100 different combinations, and use all available cores\n","rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, \n","                               cv = 3, verbose=2, random_state=42, n_jobs = -1)\n","rf_random.fit(X_train, y_train)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","rf_random.best_params_\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"," \n","\n"]}],"metadata":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.7.3 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}
